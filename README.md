# DQN-Based Traffic Signal Control for Bus Prioritization

This project implements a Deep Q-Network (DQN) reinforcement learning model to optimize traffic signal timings with a focus on prioritizing delayed public buses, using the SUMO traffic simulator.

## ğŸ¯ Objective

To investigate whether reinforcement learning can serve as a viable approach for intelligent traffic signal controlâ€”particularly one that responds to real-time traffic conditions while prioritizing delayed public buses.

## ğŸ§  Reinforcement Learning Details

- **Algorithm**: Deep Q-Network (DQN)
- **Environment**: SUMO (Simulation of Urban Mobility)
- **State Space**:
  - Queue lengths (N, E, S, W)
  - Bus lateness per direction (N, E, S, W)
  - Current traffic phase
- **Action Space**: Discrete phase choices (e.g., NS or EW green)
- **Reward Function**:
  - Penalizes bus lateness (weighted higher)
  - Penalizes traffic congestion (secondary)

## âš™ï¸ System Architecture

- **Simulation Control**: Python with TraCI API
- **Machine Learning**: TensorFlow/Keras
- **Visualisation**: Matplotlib
- **Evaluation Metrics**:
  - Average Bus Delay
  - Congestion Level
  - Total Episode Reward (RL only)

## ğŸ§ª Project Structure

```
.
â”œâ”€â”€ rlAgent.py                  # Multi-agent DQN controller
â”œâ”€â”€ testfile.py                # Single-agent test
â”œâ”€â”€ busTT.py                   # Timetable extractor
â”œâ”€â”€ busTTdisplay.py           # Timetable visualiser
â”œâ”€â”€ bus_priority_no_agent.py   # Rule-based controller
â”œâ”€â”€ bus_timetable.json         # Bus travel time logs
â”œâ”€â”€ busstop.xml                # Bus stop definitions
â”œâ”€â”€ net.net.xml                # Road network
â”œâ”€â”€ network.rou.xml            # Vehicle routes
â”œâ”€â”€ network.sumocfg            # SUMO config
â””â”€â”€ README.md
```

## ğŸš€ Running the Project

Train multi-agent DQN:
```bash
python rlAgent.py
```

Run a rule-based baseline:
```bash
python bus_priority_no_agent.py
```

Extract bus timetable data:
```bash
python busTT.py
```

Display timetable results:
```bash
python busTTdisplay.py
```

## ğŸ“¦ Requirements

Install Python dependencies:
```bash
pip install -r requirements.txt
```

### requirements.txt
```
tensorflow
keras
numpy
matplotlib
pandas
sumolib
traci
```

## ğŸ“ˆ Results Summary

- The DQN agent shows a steady reduction in congestion and an increase in total reward over episodes.
- Although the rule-based controller achieves lower bus delays, it increases congestion.
- The RL-based method balances efficiency and fairness and shows great promise with more training.

## ğŸ”® Future Work

- Multi-agent coordination for network-wide optimisation
- Integration with real-time GPS data
- Deployment in complex or real-world traffic networks

## ğŸ‘¨â€ğŸ’» Author

**Roy Zheng**  
BSc Computer Science, Trinity College Dublin  
Incoming MSc Artificial Intelligence and Data Engineering, UCL

---

## ğŸ“œ License

MIT License
